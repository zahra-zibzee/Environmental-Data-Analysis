---
title: "LiDAR Data Processing and Tree Detection"
author: "Kasra Eskandarizanjani and Zahra hashemi"
format: 
    html:
        page-layout: full
execute: 
  freeze: auto
---

<style>
    main .content {
    max-width: 1400px;
    width: 100%;
    margin: 0 auto;
}
</style>

# Introduction
In this project, we are going to work with preprocessed LiDAR point cloud data of 10 ground plots (all same size) of a forest in Russia. The goal is to identify the trees in the plots. Our group has chosen task no. 4, which first, we are going to create depth images out of point cloud datasets for each plot, segmenting the trees based on the ground truth we have for individual trees, then, we are going to apply Unet or ResNet to identify those individual trees in the depth images. 


In the cell below, you can see a visualisation of plot 1.

```{python}
import os
import numpy as np
import pandas as pd
import laspy
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
import rasterio
from rasterio.plot import show
import cv2
import json
import glob

from utils import lidar_to_point_cloud, tree_scope_definition


def visualize_lidar(lidar_file: str | os.PathLike):
    """Visualize a LiDAR point cloud file (.las or .laz)."""
    points = lidar_to_point_cloud(lidar_file)
    print(points.shape)
    fig = plt.figure(figsize=(10, 10))
    ax = fig.add_subplot(111, projection="3d")
    ax.scatter(
        points[:, 0], points[:, 1], points[:, 2], c=points[:, 2], cmap="viridis", s=0.5
    )
    ax.set_title("LiDAR Point Cloud Visualization")
    ax.set_xlabel("X")
    ax.set_ylabel("Y")
    ax.set_zlabel("Z")
    plt.show()


visualize_lidar("data/als/plot_01.las")
```


# Data Preprocessing

here, a histogram of the Z values of the point cloud is plotted. The red dashed lines represent the first and third quartiles plus/minus 1.5 times the IQR.

```{python}
points_01 = lidar_to_point_cloud("data/als/plot_01.las")
IQRz = np.percentile(points_01[:, 2], 75) - np.percentile(points_01[:, 2], 25)
plt.hist(points_01[:, 2], bins=100, color="blue", alpha=0.7)
plt.axvline(np.percentile(points_01[:, 2], 25) - 1.5 * IQRz, color="red", linestyle="--")
plt.axvline(np.percentile(points_01[:, 2], 75) + 1.5 * IQRz, color="red", linestyle="--")
plt.title("Histogram of Z Values (Plot 01)")
plt.xlabel("Z Value")
plt.ylabel("Frequency")
plt.show()
```


## General Method to Create Depth Images

Converting a point cloud (shape `(218000, 3)`, representing 3D points (x, y, z)) into a 2D depth image involves projecting the 3D points onto a 2D plane and encoding the depth information (usually the z-coordinate or distance from the camera).

Here’s how you can do it:

1. **Define the camera projection:**
   - Choose a camera's intrinsic parameters (focal length, principal point, etc.).
   - Set the resolution of the depth image (e.g., 640 \times 480).

2. **Project points to the 2D plane:**
   - Convert (x, y, z) into image coordinates (u, v) using:
     $$
     u = f_x \cdot \frac{x}{z} + c_x, \quad v = f_y \cdot \frac{y}{z} + c_y
     $$
     where f_x, f_y are the focal lengths (in pixels), and c_x, c_y are the principal points (image center).

3. **Create a depth map:**
   - Map each 3D point to its corresponding (u, v) pixel in the 2D image.
   - Store the z-value (or -z for convention) in the depth map at (u, v).
   - Handle occlusions by keeping the smallest z-value for each (u, v) to ensure only the closest point is recorded.

4. **Normalize depth values:**
   - Scale the depth values to a range suitable for visualization (e.g., 0–255 for 8-bit images).

---

## Depth Image Creation

But we don't have the camera intrinsic parameters. Since we are going to map from the top, we will use this method:

Group by x and y, and get the maximum z value. This will give us the depth map. Then we will normalize the z-values to 0-255, to get the grayscale image.

For better results, we remove the height values that are outliers. We use the IQR method to remove the outliers. 

```{python}
points = pd.DataFrame(lidar_to_point_cloud("data/als/plot_01.las"), columns=["x", "y", "z"])
points["x"] = points["x"].astype(int)
points["y"] = points["y"].astype(int)
depth_map = points.groupby(["x", "y"])["z"].max().reset_index()
Q1 = np.percentile(depth_map["z"], 25)
Q3 = np.percentile(depth_map["z"], 75)
IQR = Q3 - Q1
plt.hist(depth_map["z"], bins=100, color="b", alpha=0.7)
plt.axvline(Q1 - 1.5 * IQR, color="r", linestyle="--")
plt.axvline(Q3 + 1.5 * IQR, color="r", linestyle="--")
plt.title("Histogram of Depth Map")
plt.xlabel("Depth Value")
plt.ylabel("Frequency")
plt.show()
```

here is a representation of the depth map of plot 1.

```{python}
# Remove outliers
depth_map = depth_map[
    (depth_map["z"] >= Q1 - 1.5 * IQR) & (depth_map["z"] <= Q3 + 1.5 * IQR)
]

# convert the point cloud to a depth map
depth_map["x"] = (depth_map["x"] - depth_map["x"].min()).astype(int)
depth_map["y"] = (depth_map["y"] - depth_map["y"].min()).astype(int)
img = np.zeros((depth_map["x"].max() + 1, depth_map["y"].max() + 1)) + depth_map["z"].min()
print(img.size, img.shape)
print(depth_map.shape)
img[depth_map["x"], depth_map["y"]] = depth_map["z"]
img = (img / img.max() * 255).astype(np.uint8)

# histogram equalization
img = cv2.equalizeHist(img)

print(img, img.dtype)
# plt.hist(img.flatten(), bins=255, range=(0, 255), color="b", alpha=0.7)


plt.figure(figsize=(10, 10))
plt.imshow(img, cmap="gray")
plt.axis("off")
plt.title("Depth Map")
plt.show()
```


Now lets put everything in a function and use step as a parameter to group the points.

The above cells represent the steps we plan to take. The taken steps are outlined in the following implemented functions.

In the `tree_scope_definition` function, based on the location of individual trees in the ground truth geojson file, we label the points in the depth image that are within the circle of the tree's location and diameter. The function returns the depth image with the labeled points.

```{python}
from utils import lidar_to_point_cloud, tree_scope_definition

plot_num = 1
raw_depth_map = pd.DataFrame(
    lidar_to_point_cloud(f"data/als/plot_{plot_num:02d}.las"), columns=["x", "y", "z"]
)
gt_depth_map = tree_scope_definition(raw_depth_map, 1)
print(gt_depth_map["label"].value_counts().sort_index())
# plt.hist(gt_depth_map["label"], bins=5, color="b", alpha=0.7)
gt_depth_map
```

```{python}
from utils import take_photo_from_top


plot_num = 1
raw_depth_map = pd.DataFrame(
    lidar_to_point_cloud(f"data/als/plot_{plot_num:02d}.las"), columns=["x", "y", "z"]
)
gt_depth_map = tree_scope_definition(raw_depth_map, 1)
depth_map = take_photo_from_top(gt_depth_map, step=0.1)


plt.hist(depth_map["z"], bins=100, color="b", alpha=0.7)
plt.title("Histogram of Depth Map")
plt.xlabel("Depth Value")
plt.ylabel("Frequency")
plt.show()
```


```{python}
from utils import create_depth_img


raw_depth_map = pd.DataFrame(
    lidar_to_point_cloud("data/als/plot_01.las"), columns=["x", "y", "z"]
)
gt_depth_map = tree_scope_definition(raw_depth_map, 1)
depth_map = take_photo_from_top(gt_depth_map)
# print(depth_map.columns)
depth_img, mask, missing_pixels = create_depth_img(depth_map)

depth_img_3d = cv2.cvtColor(depth_img, cv2.COLOR_GRAY2RGB)
depth_img_3d[mask == 1] = [255, 0, 0]
# depth_img_3d[missing_pixels == 1] = [0, 0, 255]

plt.figure(figsize=(10, 10))
plt.imshow(depth_img_3d)
plt.axis("off")
plt.title("Depth Map")
plt.show()
```

The mask image is showing the identified tree points in the depth image. 

```{python}
plt.figure(figsize=(10, 10))
plt.imshow(mask, cmap="gray")
plt.axis("off")
plt.title("Mask")
plt.show()
```

## Plot Rotation (Data Preprocessing)

If we take a look at original plots, we realize that the rectangles have been rotated. 
In order to rotate the images, we will take the following steps:

To calculate the rotation angle:
    - Sort the points by their y-coordinates to distinguish the top (2 points) and bottom (the rest) points.
    - Further sort the top points by their x-coordinates.
    - To calculate the angle, use arctan2(dy, dx) where dx and dy are the differences in x and y coordinates of the top points.

    $$
    \text{atan2}(y, x) =
    \begin{cases} 
    \arctan\left(\frac{y}{x}\right) & \text{if } x > 0, \\[10pt]
    \arctan\left(\frac{y}{x}\right) + \pi & \text{if } x < 0 \text{ and } y \geq 0, \\[10pt]
    \arctan\left(\frac{y}{x}\right) - \pi & \text{if } x < 0 \text{ and } y < 0, \\[10pt]
    +\frac{\pi}{2} & \text{if } x = 0 \text{ and } y > 0, \\[10pt]
    -\frac{\pi}{2} & \text{if } x = 0 \text{ and } y < 0, \\[10pt]
    \text{undefined} & \text{if } x = 0 \text{ and } y = 0.
    \end{cases}
    $$



To rotate the points:
    - Define a rotation matrix using the angle.
    $$\begin{bmatrix}
    \cos(\theta) & -\sin(\theta) \\
    \sin(\theta) & \cos(\theta)
    \end{bmatrix}$$
    - Rotate the points using the rotation matrix:
        `rotated_points = points @ rotation_matrix`
    - Adjust the rotation based on the orientation (landscape or portrait).



```{python}

from utils import calculate_rotation_angle, turn_points

```

## Create The Depth Images for all the Data Grounds

```{python}
# | eval: false
from utils import create_dataset

all_depth_imgs, all_masks, all_missing_pixels, angles = create_dataset(
    "data/als", orientation=False
)
```

## Visualize the Depth Images - No Rotation

```{python}
# | eval: false
fig, axes = plt.subplots(5, 2, figsize=(10, 25))
axes = axes.flatten()
if len(all_depth_imgs) > len(axes):
    indices = np.random.choice(range(len(all_depth_imgs)), len(axes), replace=False)
else:
    indices = range(len(all_depth_imgs))

for i, ax in zip(indices, axes):
    depth_img, mask, missing_pixel = (
        all_depth_imgs[i],
        all_masks[i],
        all_missing_pixels[i],
    )
    depth_img_3d = cv2.cvtColor(depth_img, cv2.COLOR_GRAY2RGB)
    depth_img_3d[mask == 1] = [255, 0, 0]
    # depth_img_3d[missing_pixel == 1] = [0, 0, 255]

    ax.imshow(depth_img_3d)
    ax.axis("off")
    ax.set_title(f"Plot {i + 1}, Angle: {angles[i]:.2f}°")
plt.tight_layout()
plt.show()
```

## Visualize the Depth Images - With Rotation (Landscape)

```{python}
# | eval: false
all_depth_imgs, all_masks, all_missing_pixels, angles = create_dataset(
    "data/als", orientation="landscape")
fig, axes = plt.subplots(5, 2, figsize=(10, 25))
axes = axes.flatten()
if len(all_depth_imgs) > len(axes):
    indices = np.random.choice(range(len(all_depth_imgs)), len(axes), replace=False)
else:
    indices = range(len(all_depth_imgs))

for i, ax in zip(indices, axes):
    depth_img, mask, missing_pixel = (
        all_depth_imgs[i],
        all_masks[i],
        all_missing_pixels[i],
    )
    depth_img_3d = cv2.cvtColor(depth_img, cv2.COLOR_GRAY2RGB)
    depth_img_3d[mask == 1] = [255, 0, 0]
    # depth_img_3d[missing_pixel == 1] = [0, 0, 255]or ax, (img, mask) in zip(axes, val_loader):

    ax.imshow(depth_img_3d)
    ax.axis("off")
    ax.set_title(f"Plot {i + 1}, Angle: {angles[i]:.2f}°")
plt.tight_layout()
plt.show()
```

Let's check the images sizes:
```{python}
# | eval: false
for img in all_depth_imgs:
    print(img.shape)
``` 

These images are too big, let's split each image into several patches and use them as the input of the model.
To make sure to keep the trees in the patches, we will use overlapping patches. 

You can run `python utils.py` to create the patches and save them in the `data/patches` folder.

# Model design and training process

## Dataset

The dataset class is availabe in the `model_training.py` file. The dataset class is called `ImagesDataset` and it is used to load the images and masks from the folder where the patches are saved.


> To Have better result in the model, the dataset recieves a parameter named `extend_radius` which is used to extend the mask of the trees in the images. This is done to make sure the trees are big enough in the images to be detected by the model. The default value for this parameter is 20 pixels.
```{python}
from model_training import ImagesDataset

dataset = ImagesDataset("data/patches")

fig, axes = plt.subplots(3, 2, figsize=(10, 5))
axes = axes.flatten()
for ax, (img, mask) in zip(axes, dataset):
    print(img.shape, mask.shape)
    assert (
        mask.shape[-1] == 2
    ), f"The mask should have 2 channels, {mask.shape[0]} found."
    mask = mask.argmax(-1)
    img = np.stack([img, img, img], axis=-1)
    img[mask == 1] = [255, 0, 0]
    ax.imshow(img)
    ax.axis("off")
plt.tight_layout()
plt.show()
```

## Model Architecture - Unet
```{python}
# | echo: false
# | eval: false
import torch
import segmentation_models_pytorch as smp

# Load a pretrained U-Net model with ResNet34 backbone
model = smp.Unet(
    encoder_name="resnet34",  # choose encoder, e.g. mobilenet_v2, efficientnet-b7
    encoder_weights="imagenet",  # use pretrained weights
    in_channels=3,  # input channels (e.g. 3 for RGB)
    classes=1,
)  # output channels (e.g. 1 for binary segmentation)

# Check the model summary
print(model)
```


## Model Architecture

We took the Unet model from [this repo](https://github.com/milesial/Pytorch-UNet/tree/master/unet) and we will use it to train our model.
Here we can see the model architecture of the Unet model we are going to use.
```{python}
from model_training import setup_model

model, optimizer, criterion, device = setup_model()

print(model)
```


## Data Loading and Training

```{python}
# | eval: false
from model_training import train_model


all_train_loss, all_val_loss, model, val_loader, train_loader = train_model(
    data_folder="./data/patches",
    model_save_path="unet_model.pth",
    epochs=10,
    batch_size=16,
    learning_rate=1e-3,
)
```

```{python}
# | echo: false
print("""
ython model_training.py 
100%|████████████████████████████████████████████████████████| 115/115 [00:39<00:00,  2.90it/s]
Epoch 1/10, Train Loss: 0.1579, Val Loss: 0.0677
100%|████████████████████████████████████████████████████████| 115/115 [00:35<00:00,  3.24it/s]
Epoch 2/10, Train Loss: 0.0556, Val Loss: 0.0483
100%|████████████████████████████████████████████████████████| 115/115 [00:35<00:00,  3.25it/s]
Epoch 3/10, Train Loss: 0.0459, Val Loss: 0.0435
100%|████████████████████████████████████████████████████████| 115/115 [00:35<00:00,  3.26it/s]
Epoch 4/10, Train Loss: 0.0431, Val Loss: 0.0421
100%|████████████████████████████████████████████████████████| 115/115 [00:35<00:00,  3.28it/s]
Epoch 5/10, Train Loss: 0.0416, Val Loss: 0.0410
100%|████████████████████████████████████████████████████████| 115/115 [00:35<00:00,  3.28it/s]
Epoch 6/10, Train Loss: 0.0409, Val Loss: 0.0405
100%|████████████████████████████████████████████████████████| 115/115 [00:34<00:00,  3.29it/s]
Epoch 7/10, Train Loss: 0.0404, Val Loss: 0.0401
100%|████████████████████████████████████████████████████████| 115/115 [00:35<00:00,  3.27it/s]
Epoch 8/10, Train Loss: 0.0400, Val Loss: 0.0397
100%|████████████████████████████████████████████████████████| 115/115 [00:35<00:00,  3.27it/s]
Epoch 9/10, Train Loss: 0.0395, Val Loss: 0.0408
100%|████████████████████████████████████████████████████████| 115/115 [00:34<00:00,  3.29it/s]
Epoch 10/10, Train Loss: 0.0390, Val Loss: 0.0399
Model saved to unet_model.pth
Train and validation loss saved to train_val_loss.npy
""")
```
```{python}
# | echo: false

from model_training import create_dataset

train_val_loss = np.load("train_val_loss.npy")
all_train_loss, all_val_loss = train_val_loss[0], train_val_loss[1]

train_loader, val_loader = create_dataset("data/patches", batch_size=16)
```

```{python}
plt.figure(figsize=(10, 5))
plt.plot(all_train_loss, label="Train Loss")
plt.plot(all_val_loss, label="Validation Loss")
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.title("Training and Validation Loss")
plt.legend()
plt.show()
```

## Model Evaluation
```{python}
# | echo: false
import torch
from model_training import UNet

model, optimizer, criterion, device = setup_model()
model.load_state_dict(
    torch.load("unet_model.pth", map_location=device, weights_only=True)
)
model.eval()
print(None)
```

```{python}
fig, axes = plt.subplots(4, 3, figsize=(10, 10))
legend_elements = [
    plt.Line2D(
        [0],
        [0],
        marker="o",
        color="w",
        markerfacecolor="green",
        markersize=10,
        label="Predicted",
    ),
    plt.Line2D(
        [0],
        [0],
        marker="o",
        color="w",
        markerfacecolor="red",
        markersize=10,
        label="Ground Truth",
    ),
]

axes[0, -1].legend(
    handles=legend_elements, loc="center left", bbox_to_anchor=(1.1, 0.5)
)

axes = axes.flatten()

for ax, (img, mask) in zip(axes, val_loader):
    img = img.to(device)
    mask = mask.to(device)
    pred = model(img).detach().cpu()
    img = img[0].squeeze(0).cpu().numpy()
    img = (img - img.min()) / (img.max() - img.min()) * 255
    mask = mask[0].squeeze(0).cpu().numpy().argmax(0)
    pred = pred[0].squeeze(0).cpu().numpy().argmax(0)
    img = np.stack([img, img, img], axis=-1).astype(np.uint8)
    img[mask == 1] = [255, 0, 0]
    img[pred == 1] = [0, 255, 0]
    ax.imshow(img)
    ax.axis("off")


plt.tight_layout()
plt.show()
```

In this pint 
## Performance evaluation and insights

???


## Baseline Model (Local Maxima Filtering)

```{python}
import scipy.spatial


def local_maxima_filter(cloud: np.ndarray, window_size: float) -> np.ndarray:
    """Detect local maxima in the point cloud with a fixed window size."""

    assert isinstance(
        cloud, np.ndarray
    ), f"Cloud needs to be a numpy array, not {type(cloud)}"

    # cloud = cloud[cloud[:, 2] > height_threshold]
    tree = scipy.spatial.KDTree(data=cloud)
    seen_mask = np.zeros(cloud.shape[0], dtype=bool)
    local_maxima = []

    for i, point in enumerate(cloud):
        if seen_mask[i]:
            continue
        neighbor_indices = tree.query_ball_point(point, window_size)
        highest_neighbor = neighbor_indices[cloud[neighbor_indices, 2].argmax()]
        seen_mask[neighbor_indices] = True
        seen_mask[highest_neighbor] = False
        # This may lead to not every point being marked as seed in the end, but it does not matter,
        # because by the time the seen value is overwritten the point is already processed
        if i == highest_neighbor:
            local_maxima.append(i)

    return cloud[local_maxima]

```

```{python}

def read_geojason_by_plot(file_path: str | os.PathLike, plot_num: int) -> pd.DataFrame:
    with open(file_path) as f:
        data = json.load(f)
    data = pd.DataFrame([i["properties"] | i['geometry'] for i in data["features"]])
    data['x'] = data['coordinates'].apply(lambda x: x[0])
    data['y'] = data['coordinates'].apply(lambda x: x[1])
    data = data.drop(columns=['coordinates'])

    # filter data by plot number
    data = data[data["plot"] == plot_num]
    return data

def test_local_maxima(window_sizes: list):
    for plot_num in range(1, 11):
        print(f"Plot {plot_num}")
        gt_data = read_geojason_by_plot("data/field_survey.geojson", plot_num)
        points = laspy.read(f"data/als/plot_{plot_num:02d}.las")
        for window_size in window_sizes:
            lm_points = local_maxima_filter(points.xyz, window_size)
            point_distances = []
            for lm_point in lm_points:
                min_distance = np.inf
                for gt_point in gt_data[['x', 'y']].values:
                    distance = np.linalg.norm(lm_point[:2] - gt_point)
                    if distance < min_distance:
                        min_distance = distance
                point_distances.append(min_distance)
            point_distances = [float(distance) for distance in point_distances]
            print(f"Window size: {window_size}")
            # print("Sum distance:", np.sum(point_distances))
            # print("Median distance:", np.median(point_distances))
            print("local maxima filter (number of trees):", lm_points.shape[0])
            print("ground truth (number of trees):", gt_data.shape[0])
        # plt.figure(figsize=(10, 5))
        # plt.hist(point_distances, bins=20, color='skyblue', edgecolor='black')
        # plt.xlabel('Distance to nearest ground truth point')
        # plt.ylabel('Frequency')
        # plt.show()

test_local_maxima([3])
```