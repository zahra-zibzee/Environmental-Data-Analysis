---
title: "LiDAR Data Processing and Tree Detection"
execute: 
  freeze: true
---

<style>
    main .content {
    max-width: 1400px;
    width: 100%;
    margin: 0 auto;
}
</style>

# Introduction
In this project, we are going to work with preprocessed LiDAR point cloud data of 10 ground plots (all same size) of a forest in Russia. The goal is to identify the trees in the plots. Our group has chosen task no. 4, which first, we are going to create depth images out of point cloud datasets for each plot, segmenting the trees based on the ground truth we have for individual trees, then, we are going to apply Unet or ResNet to identify those individual trees in the depth images. 


In the cell below, you can see a visualisation of plot 1.

```{python}
import os
import numpy as np
import pandas as pd
import laspy
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
import rasterio
from rasterio.plot import show
import cv2
import json
import glob


def lidar_to_point_cloud(lidar_file: str | os.PathLike) -> np.ndarray:
    """Read a LiDAR file and return a NumPy array of points."""
    las = laspy.read(lidar_file)
    points = np.vstack((las.x, las.y, las.z)).transpose()
    return points


def visualize_lidar(lidar_file: str | os.PathLike):
    """Visualize a LiDAR point cloud file (.las or .laz)."""
    points = lidar_to_point_cloud(lidar_file)
    print(points.shape)
    fig = plt.figure(figsize=(10, 10))
    ax = fig.add_subplot(111, projection="3d")
    ax.scatter(
        points[:, 0], points[:, 1], points[:, 2], c=points[:, 2], cmap="viridis", s=0.5
    )
    ax.set_title("LiDAR Point Cloud Visualization")
    ax.set_xlabel("X")
    ax.set_ylabel("Y")
    ax.set_zlabel("Z")
    plt.show()


visualize_lidar("data/als/plot_01.las")
```


# Data Preprocessing

here, a histogram of the Z values of the point cloud is plotted. The red dashed lines represent the first and third quartiles plus/minus 1.5 times the IQR.

```{python}
points_01 = lidar_to_point_cloud("data/als/plot_01.las")
IQRz = np.percentile(points_01[:, 2], 75) - np.percentile(points_01[:, 2], 25)
plt.hist(points_01[:, 2], bins=100, color="blue", alpha=0.7)
plt.axvline(np.percentile(points_01[:, 2], 25) - 1.5 * IQRz, color="red", linestyle="--")
plt.axvline(np.percentile(points_01[:, 2], 75) + 1.5 * IQRz, color="red", linestyle="--")
plt.title("Histogram of Z Values (Plot 01)")
plt.xlabel("Z Value")
plt.ylabel("Frequency")
plt.show()
```


## General Method to Create Depth Images

Converting a point cloud (shape `(218000, 3)`, representing 3D points (x, y, z)) into a 2D depth image involves projecting the 3D points onto a 2D plane and encoding the depth information (usually the z-coordinate or distance from the camera).

Here’s how you can do it:

1. **Define the camera projection:**
   - Choose a camera's intrinsic parameters (focal length, principal point, etc.).
   - Set the resolution of the depth image (e.g., 640 \times 480).

2. **Project points to the 2D plane:**
   - Convert (x, y, z) into image coordinates (u, v) using:
     $$
     u = f_x \cdot \frac{x}{z} + c_x, \quad v = f_y \cdot \frac{y}{z} + c_y
     $$
     where f_x, f_y are the focal lengths (in pixels), and c_x, c_y are the principal points (image center).

3. **Create a depth map:**
   - Map each 3D point to its corresponding (u, v) pixel in the 2D image.
   - Store the z-value (or -z for convention) in the depth map at (u, v).
   - Handle occlusions by keeping the smallest z-value for each (u, v) to ensure only the closest point is recorded.

4. **Normalize depth values:**
   - Scale the depth values to a range suitable for visualization (e.g., 0–255 for 8-bit images).

---

## Depth Image Creation

But we don't have the camera intrinsic parameters. Since we are going to map from the top, we will use this method:

Group by x and y, and get the maximum z value. This will give us the depth map. Then we will normalize the z-values to 0-255, to get the grayscale image.

For better results, we remove the height values that are outliers. We use the IQR method to remove the outliers. 

```{python}
points = pd.DataFrame(lidar_to_point_cloud("data/als/plot_01.las"), columns=["x", "y", "z"])
points["x"] = points["x"].astype(int)
points["y"] = points["y"].astype(int)
depth_map = points.groupby(["x", "y"])["z"].max().reset_index()
Q1 = np.percentile(depth_map["z"], 25)
Q3 = np.percentile(depth_map["z"], 75)
IQR = Q3 - Q1
plt.hist(depth_map["z"], bins=100, color="b", alpha=0.7)
plt.axvline(Q1 - 1.5 * IQR, color="r", linestyle="--")
plt.axvline(Q3 + 1.5 * IQR, color="r", linestyle="--")
plt.title("Histogram of Depth Map")
plt.xlabel("Depth Value")
plt.ylabel("Frequency")
plt.show()
```

here is a representation of the depth map of plot 1.

```{python}
# Remove outliers
depth_map = depth_map[
    (depth_map["z"] >= Q1 - 1.5 * IQR) & (depth_map["z"] <= Q3 + 1.5 * IQR)
]

# convert the point cloud to a depth map
depth_map["x"] = (depth_map["x"] - depth_map["x"].min()).astype(int)
depth_map["y"] = (depth_map["y"] - depth_map["y"].min()).astype(int)
img = np.zeros((depth_map["x"].max() + 1, depth_map["y"].max() + 1)) + depth_map["z"].min()
print(img.size, img.shape)
print(depth_map.shape)
img[depth_map["x"], depth_map["y"]] = depth_map["z"]
img = (img / img.max() * 255).astype(np.uint8)

# histogram equalization
img = cv2.equalizeHist(img)

print(img, img.dtype)
# plt.hist(img.flatten(), bins=255, range=(0, 255), color="b", alpha=0.7)


plt.figure(figsize=(10, 10))
plt.imshow(img, cmap="gray")
plt.axis("off")
plt.title("Depth Map")
plt.show()
```


Now lets put everything in a function and use step as a parameter to group the points.

The above cells represent the steps we plan to take. The taken steps are outlined in the following implemented functions.

In the `tree_scope_definition` function, based on the location of individual trees in the ground truth geojson file, we label the points in the depth image that are within the circle of the tree's location and diameter. The function returns the depth image with the labeled points.

```{python}
from functools import lru_cache

@lru_cache
def read_geojson(geojson_address: str | os.PathLike = "data/field_survey.geojson") -> pd.DataFrame:
    """Read a geojson file into a DataFrame."""
    with open(geojson_address) as f:
        data = json.load(f)
    data = pd.DataFrame([i["properties"] | i["geometry"] for i in data["features"]])
    data["x"] = data["coordinates"].apply(lambda x: x[0])
    data["y"] = data["coordinates"].apply(lambda x: x[1])
    data = data.drop(columns=["coordinates"])
    return data


def tree_scope_definition(
    depth_img_df: pd.DataFrame,
    plot_num: int,
    geojson_address: str | os.PathLike = "data/field_survey.geojson",
) -> pd.DataFrame:
    data = read_geojson(geojson_address)
    data = data[data["plot"] == plot_num]

    depth_img_df = depth_img_df.drop_duplicates().copy()
    depth_img_df["label"] = 0

    # label data points from depth_img_df that are in the circle, with the center of x, y and radius of dbh from data
    not_founed_trees = 0
    not_founed_trees_r = []

    for index, row in data.iterrows():
        x, y, r = row["x"], row["y"], row["dbh"]
        r /= 100  # converting dbh to meters and dividing by 2 to get the radius
        # tmp = depth_img_df[
        #     (depth_img_df["x"] >= x - r)
        #     & (depth_img_df["x"] <= x + r)
        #     & (depth_img_df["y"] >= y - r)
        #     & (depth_img_df["y"] <= y + r)
        # ]
        distances = np.sqrt(
            (depth_img_df["x"] - x) ** 2 + (depth_img_df["y"] - y) ** 2
        ).sort_values()
        # tmp = distances.iloc[:40]
        tmp = distances[distances <= r]
        if tmp.empty:
            # print(f"No points in the circle with center {x, y} and radius {r}")
            not_founed_trees += 1
            not_founed_trees_r.append(r)
            continue
        # adding label to the points in the circle
        depth_img_df.loc[tmp.index, "label"] = index
        # assert (
        #     depth_img_df.groupby(["x", "y"])["label"].count().max() == 1
        # ), f"There are multiple points in the same x, y, {tmp}, {index}"
        # print("dede")
    # print(f"{not_founed_trees} trees were not found in the depth image")
    # print("The average radius of the not found trees is:", np.mean(not_founed_trees_r))
    return depth_img_df


plot_num = 1
raw_depth_map = pd.DataFrame(
    lidar_to_point_cloud(f"data/als/plot_{plot_num:02d}.las"), columns=["x", "y", "z"]
)
gt_depth_map = tree_scope_definition(raw_depth_map, 1)
print(gt_depth_map["label"].value_counts().sort_index())
# plt.hist(gt_depth_map["label"], bins=5, color="b", alpha=0.7)
gt_depth_map
```

```{python}
def take_photo_from_top(points, step=0.1, remove_outliers=True):
    """Take a photo from the top of the 3D points."""
    points = points.copy()
    assert "x" in points.columns and "y" in points.columns and "z" in points.columns
    assert step > 0
    # assert (
    #     a := points.groupby(["x", "y"])["label"].nunique()
    # ).max() == 1, f"There are multiple points in the same x, y, but {a[a > 1]} has multiple points "
    # print(points)
    points[["x", "y"]] = points[["x", "y"]] // step * step
    depth_map = points.groupby(["x", "y"])[["z", "label"]].max().reset_index()
    if remove_outliers:
        Q1 = np.percentile(depth_map["z"], 25)
        Q3 = np.percentile(depth_map["z"], 75)
        IQR = Q3 - Q1
        depth_map = depth_map[
            (depth_map["z"] >= Q1 - 1.5 * IQR) & (depth_map["z"] <= Q3 + 1.5 * IQR)
        ]
    # add back the label column using join
    # depth_map["label"] = 0
    # depth_map = points[["x", "y", "z"]].merge(depth_map, on=["x", "y"], how="left")
    return depth_map


plot_num = 1
raw_depth_map = pd.DataFrame(
    lidar_to_point_cloud(f"data/als/plot_{plot_num:02d}.las"), columns=["x", "y", "z"]
)
gt_depth_map = tree_scope_definition(raw_depth_map, 1)
depth_map = take_photo_from_top(gt_depth_map, step=0.1)


plt.hist(depth_map["z"], bins=100, color="b", alpha=0.7)
plt.title("Histogram of Depth Map")
plt.xlabel("Depth Value")
plt.ylabel("Frequency")
plt.show()
```


```{python}
def create_depth_img(depth_map: pd.DataFrame) -> np.ndarray:
    """Create a depth map from 3D points."""

    for col in ["x", "y", "z"]:
        depth_map[col] -= depth_map[col].min()
        # we can not ues depth_map -= depth_map.min() because we need to preserve the columns dtypes
        # and also, we dnot want to do it for all columns
    # the xmapper and y_mapper are used to map the x and y values to the image
    x_mapper = {v: i for i, v in enumerate(sorted(depth_map["x"].unique()))}
    y_mapper = {v: i for i, v in enumerate(sorted(depth_map["y"].unique()))}
    depth_map["x_index"] = depth_map["x"].map(x_mapper)
    depth_map["y_index"] = depth_map["y"].map(y_mapper)
    img = np.zeros((len(x_mapper), len(y_mapper)))
    img[depth_map["x_index"], depth_map["y_index"]] = depth_map["z"]
    img = (img / img.max() * 255).astype(np.uint8)
    img = cv2.equalizeHist(img)

    mask = np.zeros((len(x_mapper), len(y_mapper)))
    tree_depth_map = depth_map[depth_map["label"] != 0]
    mask[tree_depth_map["x_index"], tree_depth_map["y_index"]] = 1
    # print(img.shape)

    missing_pixels = np.ones_like(img)
    missing_pixels[depth_map["x_index"], depth_map["y_index"]] = 0

    return img, mask, missing_pixels


raw_depth_map = pd.DataFrame(
    lidar_to_point_cloud("data/als/plot_01.las"), columns=["x", "y", "z"]
)
gt_depth_map = tree_scope_definition(raw_depth_map, 1)
depth_map = take_photo_from_top(gt_depth_map)
# print(depth_map.columns)
depth_img, mask, missing_pixels = create_depth_img(depth_map)

depth_img_3d = cv2.cvtColor(depth_img, cv2.COLOR_GRAY2RGB)
depth_img_3d[mask == 1] = [255, 0, 0]
# depth_img_3d[missing_pixels == 1] = [0, 0, 255]

plt.figure(figsize=(10, 10))
plt.imshow(depth_img_3d)
plt.axis("off")
plt.title("Depth Map")
plt.show()
```

The mask image is showing the identified tree points in the depth image. 

```{python}
plt.figure(figsize=(10, 10))
plt.imshow(mask, cmap="gray")
plt.axis("off")
plt.title("Mask")
plt.show()
```

## Plot Rotation (Data Preprocessing)

If we take a look at original plots, we realize that the rectangles have been rotated. 
In order to rotate the images, we will take the following steps:

To calculate the rotation angle:
    - Sort the points by their y-coordinates to distinguish the top (2 points) and bottom (the rest) points.
    - Further sort the top points by their x-coordinates.
    - To calculate the angle, use arctan2(dy, dx) where dx and dy are the differences in x and y coordinates of the top points.

    $$
    \[
    \text{atan2}(y, x) =
    \begin{cases} 
    \arctan\left(\frac{y}{x}\right) & \text{if } x > 0, \\[10pt]
    \arctan\left(\frac{y}{x}\right) + \pi & \text{if } x < 0 \text{ and } y \geq 0, \\[10pt]
    \arctan\left(\frac{y}{x}\right) - \pi & \text{if } x < 0 \text{ and } y < 0, \\[10pt]
    +\frac{\pi}{2} & \text{if } x = 0 \text{ and } y > 0, \\[10pt]
    -\frac{\pi}{2} & \text{if } x = 0 \text{ and } y < 0, \\[10pt]
    \text{undefined} & \text{if } x = 0 \text{ and } y = 0.
    \end{cases}
    \]
    $$



To rotate the points:
    - Define a rotation matrix using the angle.
    $$\begin{bmatrix}
    \cos(\theta) & -\sin(\theta) \\
    \sin(\theta) & \cos(\theta)
    \end{bmatrix}$$
    - Rotate the points using the rotation matrix:
        `rotated_points = points @ rotation_matrix`
    - Adjust the rotation based on the orientation (landscape or portrait).



```{python}

def calculate_rotation_angle(points, orientation="landscape"):
    """
    Calculate the angle of rotation for a quadrilateral based on its four corner points.

    Parameters:
    points (list or np.ndarray): A list or array of four points, each represented as [x, y].
                                 The points should be in any order.
    orientation (str): The orientation of the quadrilateral. Can be either "landscape" or "vertical".

    Returns:
    float: The rotation angle (in degrees) of the top edge with respect to the horizontal axis.
    """
    # Ensure points are a NumPy array
    points = np.array(points)

    # Sort points by their y-coordinates (to distinguish top and bottom)
    points = points[np.argsort(points[:, 1])]

    # Extract top and bottom points
    top_points = points[:2]  # First two are the top points
    bottom_points = points[2:]  # Last two are the bottom points

    # Further sort top and bottom points by their x-coordinates
    top_left, top_right = top_points[np.argsort(top_points[:, 0])]
    bottom_left, bottom_right = bottom_points[np.argsort(bottom_points[:, 0])]

    # Calculate the angle of the top edge
    dx = top_right[0] - top_left[0]
    dy = top_right[1] - top_left[1]
    angle = np.degrees(np.arctan2(dy, dx))

    # Adjust the angle based on the orientation
    if orientation == "landscape" and abs(dx) < abs(dy):  # If height > width
        angle += 90 if dy > 0 else -90
    elif orientation == "portrait" and abs(dx) > abs(dy):  # If width > height
        angle += 90 if dx > 0 else -90

    return angle

def turn_points(points, angle, orientation = "landscape"):
    """
    Rotate a set of points by a given angle around the origin.

    Parameters:
    points (np.ndarray): An array of points, each represented as [x, y].
    angle (float): The angle of rotation (in degrees).
    orientation (str): The orientation of the quadrilateral. Can be either "landscape" or "vertical".

    Returns:
    np.ndarray: An array of rotated points.
    """
    if isinstance(points, pd.DataFrame):
        columns = points.columns
        points = points.values
    else:
        columns = None

    angle = np.radians(angle)

    # Define the rotation matrix
    rotation_matrix = np.array(
        [[np.cos(angle), -np.sin(angle)], [np.sin(angle), np.cos(angle)]]
    )

    # Rotate the points
    rotated_points = points @ rotation_matrix

    width = rotated_points[:, 0].max() - rotated_points[:, 0].min()
    height = rotated_points[:, 1].max() - rotated_points[:, 1].min()

    if (orientation == "landscape" and height < width) or (orientation == "portrait" and width < height):
        rotated_points = rotated_points[:, ::-1]

    if columns is not None:
        rotated_points = pd.DataFrame(rotated_points, columns=columns)

    return rotated_points


```

## Create The Depth Images for all the Data Grounds

```{python}
def create_dataset(
    data_folder: str | os.PathLike,
    step: float = 0.1,
    remove_outliers: bool = True,
    orientation: str = "landscape",
) -> tuple[list[np.ndarray], list[np.ndarray], list[np.ndarray]]:
    """Create a dataset from the LiDAR data."""
    depth_imgs, masks, missing_pixels, angles = [], [], [], []
    for las_file in glob.glob(os.path.join(data_folder, "*.las")):
        plot_num = int(os.path.splitext(os.path.basename(las_file))[0].split("_")[-1])
        raw_depth_map = pd.DataFrame(
            lidar_to_point_cloud(las_file), columns=["x", "y", "z"]
        )
        gt_depth_map = tree_scope_definition(raw_depth_map, plot_num)

        most_left_point = gt_depth_map.loc[gt_depth_map["x"].idxmin()]
        most_right_point = gt_depth_map.loc[gt_depth_map["x"].idxmax()]

        most_bottom_point = gt_depth_map.loc[gt_depth_map["y"].idxmin()]
        most_top_point = gt_depth_map.loc[gt_depth_map["y"].idxmax()]

        if orientation:
            angle = calculate_rotation_angle(
                [
                    [most_left_point["x"], most_left_point["y"]],
                    [most_right_point["x"], most_right_point["y"]],
                    [most_bottom_point["x"], most_bottom_point["y"]],
                    [most_top_point["x"], most_top_point["y"]],
                ]
            )

            gt_depth_map[["x", "y"]] = turn_points(gt_depth_map[["x", "y"]], angle)
        else:
            angle = 0

        depth_map = take_photo_from_top(
            gt_depth_map, step=step, remove_outliers=remove_outliers
        )
        depth_img, mask, missing_pixel = create_depth_img(depth_map)
        depth_imgs.append(depth_img)
        masks.append(mask)
        missing_pixels.append(missing_pixel)
        angles.append(angle)
    return depth_imgs, masks, missing_pixels, angles


all_depth_imgs, all_masks, all_missing_pixels, angles = create_dataset(
    "data/als", orientation=False)

```

## Visualize the Depth Images - No Rotation

```{python}
fig, axes = plt.subplots(5, 2, figsize=(10, 25))
axes = axes.flatten()
if len(all_depth_imgs) > len(axes):
    indices = np.random.choice(range(len(all_depth_imgs)), len(axes), replace=False)
else:
    indices = range(len(all_depth_imgs))

for i, ax in zip(indices, axes):
    depth_img, mask, missing_pixel = (
        all_depth_imgs[i],
        all_masks[i],
        all_missing_pixels[i],
    )
    depth_img_3d = cv2.cvtColor(depth_img, cv2.COLOR_GRAY2RGB)
    depth_img_3d[mask == 1] = [255, 0, 0]
    # depth_img_3d[missing_pixel == 1] = [0, 0, 255]

    ax.imshow(depth_img_3d)
    ax.axis("off")
    ax.set_title(f"Plot {i + 1}, Angle: {angles[i]:.2f}°")
plt.tight_layout()
plt.show()
```

## Visualize the Depth Images - With Rotation (Landscape)

```{python}
all_depth_imgs, all_masks, all_missing_pixels, angles = create_dataset(
    "data/als", orientation="landscape")
fig, axes = plt.subplots(5, 2, figsize=(10, 25))
axes = axes.flatten()
if len(all_depth_imgs) > len(axes):
    indices = np.random.choice(range(len(all_depth_imgs)), len(axes), replace=False)
else:
    indices = range(len(all_depth_imgs))

for i, ax in zip(indices, axes):
    depth_img, mask, missing_pixel = (
        all_depth_imgs[i],
        all_masks[i],
        all_missing_pixels[i],
    )
    depth_img_3d = cv2.cvtColor(depth_img, cv2.COLOR_GRAY2RGB)
    depth_img_3d[mask == 1] = [255, 0, 0]
    # depth_img_3d[missing_pixel == 1] = [0, 0, 255]

    ax.imshow(depth_img_3d)
    ax.axis("off")
    ax.set_title(f"Plot {i + 1}, Angle: {angles[i]:.2f}°")
plt.tight_layout()
plt.show()
```

Let's check the images sizes:
```{python}
for img in all_depth_imgs:
    print(img.shape)
``` 

These images are too big, let's split each image into several patches and use them as the input of the model.

```{python}
def split_image_into_patches(
    img: np.ndarray, patch_size: tuple[int, int], stride: int = None
) -> list[np.ndarray]:
    """Split an image into patches."""
    if stride is None:
        stride = patch_size[0] // 2

    patches = []
    for i in range(0, img.shape[0] - patch_size[0] + 1, stride):
        for j in range(0, img.shape[1] - patch_size[1] + 1, stride):
            patch = img[i : i + patch_size[0], j : j + patch_size[1]]
            assert (
                patch.shape == patch_size
            ), f"Patch shape is {patch.shape}, expected {patch_size}"
            patches.append(patch)
    return patches


all_depth_patches = []
for depth_img in all_depth_imgs:
    all_depth_patches.extend(split_image_into_patches(depth_img, (128, 128)))
x_data = np.array(all_depth_patches)

all_mask_patches = []
for mask in all_masks:
    all_mask_patches.extend(split_image_into_patches(mask, (128, 128)))
y_data = np.array(all_mask_patches)
# all_missing_pixel_patches = [
#     split_image_into_patches(missing_pixel, (128, 128))
#     for missing_pixel in all_missing_pixels
# ]
```

```{python}
x_data.shape, y_data.shape
```


# Model design and training process

## Model Architecture - Unet
```{python}
# | echo: false
# | eval: false
import torch
import segmentation_models_pytorch as smp

# Load a pretrained U-Net model with ResNet34 backbone
model = smp.Unet(
    encoder_name="resnet34",  # choose encoder, e.g. mobilenet_v2, efficientnet-b7
    encoder_weights="imagenet",  # use pretrained weights
    in_channels=3,  # input channels (e.g. 3 for RGB)
    classes=1,
)  # output channels (e.g. 1 for binary segmentation)

# Check the model summary
print(model)
```

We took the Unet model from [this repo](https://github.com/milesial/Pytorch-UNet/tree/master/unet) and we will use it to train our model.


## Data Loading and Training

```{python}
from model_training import train_model

all_train_loss, all_val_loss = train_model(x_data, y_data, model_save_path='unet_model.pth', epochs=10, batch_size=16, learning_rate=1e-3)

```

```{python}
plt.figure(figsize=(10, 5))
plt.plot(all_train_loss, label="Train Loss")
plt.plot(all_val_loss, label="Validation Loss")
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.title("Training and Validation Loss")
plt.legend()
plt.show()
```

## Model Evaluation
```{python}
from model_training import UNet

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = UNet(n_channels=1, n_classes=2)
print(model)
model.load_state_dict(torch.load('unet_model.pth', map_location=device))
model.eval()

```

## Dataset

```{python}
import torch
from torch.utils.data import Dataset, DataLoader, random_split
from torchvision import transforms


class VariableSegmentationDataset(Dataset):
    def __init__(
        self,
        x_data: torch.Tensor,
        y_data: torch.Tensor,
        transform: transforms.Compose = None,
    ):
        self.x_data = x_data
        self.y_data = y_data
        self.transform = transform
        assert len(self.x_data) == len(self.y_data), "Mismatch between images and masks"

    def __len__(self) -> int:
        return len(self.x_data)

    def __getitem__(self, idx: int) -> tuple[torch.Tensor, torch.Tensor]:
        x = self.x_data[idx]
        y = self.y_data[idx]
        if self.transform:
            x = self.transform(x)
            y = self.transform(y)
        return x, y


dataset = VariableSegmentationDataset(
    torch.from_numpy(x_data).unsqueeze(1).float(),
    torch.from_numpy(y_data).unsqueeze(1).float(),
    transform=None,
)
b_size = 4
n = 3
dataloader = DataLoader(dataset, batch_size=b_size, shuffle=True)

fig, axes = plt.subplots(n, b_size, figsize=(10, 10))
for ax_line, (x_batch, y_batch) in zip(axes, dataloader):
    assert x_batch.shape[0] == b_size, f"Expected batch size {b_size}, got {x.shape[0]}"
    for x, y, ax in zip(x_batch, y_batch, ax_line):
        assert x.shape[0] == 1, f"Expected 1 channel, got {x.shape[0]}"
        x = x.squeeze(0).numpy()
        y = y.squeeze(0).numpy()
        x = np.stack([x, x, x], axis=-1)
        x[y == 1] = [1, 0, 0]
        ax.imshow(x.astype(np.uint8), cmap="gray")
        ax.axis("off")
plt.tight_layout()
plt.show()
```

## Training

```{python}
from torch import nn, optim
from tqdm import tqdm


def train_one_epoch(
    model: nn.Module,
    dataloader: DataLoader,
    optimizer: optim.Optimizer,
    criterion: nn.Module,
    device: torch.device,
) -> float:
    model.train()
    epoch_loss = 0.0
    for x, y in tqdm(dataloader):
        x, y = x.to(device), y.to(device)
        optimizer.zero_grad()
        outputs = model(x)
        loss = criterion(outputs, y)
        loss.backward()
        optimizer.step()
        epoch_loss += loss.item()
    return epoch_loss / len(dataloader)


def validate(
    model: nn.Module, dataloader: DataLoader, criterion: nn.Module, device: torch.device
) -> float:
    model.eval()
    val_loss = 0.0
    with torch.no_grad():
        for x, y in dataloader:
            x, y = x.to(device), y.to(device)
            outputs = model(x)
            loss = criterion(outputs, y)
            val_loss += loss.item()
    return val_loss / len(dataloader)


transform = transforms.Compose(
    [transforms.ToTensor(), transforms.Normalize(mean=[0.5], std=[0.5])]
)

dataset = VariableSegmentationDataset(x_data, y_data, transform=transform)

train_size = int(0.8 * len(dataset))
val_size = len(dataset) - train_size
train_dataset, val_dataset = random_split(dataset, [train_size, val_size])

train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)

# Model setup
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = UNet(n_channels=1, n_classes=1).to(device)
optimizer = optim.Adam(model.parameters(), lr=1e-3)
# criterion = nn.BCEWithLogitsLoss()
criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([2.0]).to(device))

all_train_loss, all_val_loss = [], []
epochs = 10
for epoch in range(epochs):
    train_loss = train_one_epoch(model, train_loader, optimizer, criterion, device)
    val_loss = validate(model, val_loader, criterion, device)
    all_train_loss.append(train_loss)
    all_val_loss.append(val_loss)

    print(
        f"Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}"
    )
```


## Inference

```{python}
def predict(model, x, device):
    model.eval()
    with torch.no_grad():
        # x = x.unsqueeze(0).to(device)
        x = x.to(device)
        pred = model(x)
        pred = torch.sigmoid(pred)
        pred = (pred > 0.5).float()
    return pred.squeeze(0)


fig, axes = plt.subplots(1, 2, figsize=(10, 5))
inference_dataloder = DataLoader(val_dataset, batch_size=1, shuffle=False)

for ax, (x, y) in zip(axes, inference_dataloder):
    pred = predict(model, x, device)
    x = x.squeeze().numpy()
    y = y.squeeze().numpy()
    pred = pred.squeeze(0).cpu().numpy()
    x = (x - x.min()) / (x.max() - x.min())
    x = np.stack([x, x, x], axis=-1)
    x[y == 1] = [1, 0, 0]
    x[pred == 1] = [0, 1, 0]
    print(np.unique(pred))
    # ax.imshow(x)
    ax.imshow(pred, cmap="gray")
    ax.axis("off")
plt.tight_layout()
plt.show()
```

## Performance evaluation and insights

???


## Baseline Model (Local Maxima Filtering)

```{python}
import scipy.spatial

def local_maxima_filter(cloud: np.ndarray, window_size: float) -> np.ndarray:
    """Detect local maxima in the point cloud with a fixed window size."""
    
    assert isinstance(cloud, np.ndarray), f"Cloud needs to be a numpy array, not {type(cloud)}"
    
    # cloud = cloud[cloud[:, 2] > height_threshold]
    tree = scipy.spatial.KDTree(data=cloud)
    seen_mask = np.zeros(cloud.shape[0], dtype=bool)
    local_maxima = []

    for i, point in enumerate(cloud):
        if seen_mask[i]:
            continue
        neighbor_indices = tree.query_ball_point(point, window_size)
        highest_neighbor = neighbor_indices[cloud[neighbor_indices, 2].argmax()]
        seen_mask[neighbor_indices] = True
        seen_mask[highest_neighbor] = False 
        # This may lead to not every point being marked as seed in the end, but it does not matter,
        # because by the time the seen value is overwritten the point is already processed
        if i == highest_neighbor:
            local_maxima.append(i)

    return cloud[local_maxima]

```

```{python}

def read_geojason_by_plot(file_path: str | os.PathLike, plot_num: int) -> pd.DataFrame:
    with open(file_path) as f:
        data = json.load(f)
    data = pd.DataFrame([i["properties"] | i['geometry'] for i in data["features"]])
    data['x'] = data['coordinates'].apply(lambda x: x[0])
    data['y'] = data['coordinates'].apply(lambda x: x[1])
    data = data.drop(columns=['coordinates'])

    # filter data by plot number
    data = data[data["plot"] == plot_num]
    return data

def test_local_maxima(window_sizes: list):
    for plot_num in range(1, 11):
        print(f"Plot {plot_num}")
        gt_data = read_geojason_by_plot("data/field_survey.geojson", plot_num)
        points = laspy.read(f"data/als/plot_{plot_num:02d}.las")
        for window_size in window_sizes:
            lm_points = local_maxima_filter(points.xyz, window_size)
            point_distances = []
            for lm_point in lm_points:
                min_distance = np.inf
                for gt_point in gt_data[['x', 'y']].values:
                    distance = np.linalg.norm(lm_point[:2] - gt_point)
                    if distance < min_distance:
                        min_distance = distance
                point_distances.append(min_distance)
            point_distances = [float(distance) for distance in point_distances]
            print(f"Window size: {window_size}")
            # print("Sum distance:", np.sum(point_distances))
            # print("Median distance:", np.median(point_distances))
            print("local maxima filter (number of trees):", lm_points.shape[0])
            print("ground truth (number of trees):", gt_data.shape[0])
        # plt.figure(figsize=(10, 5))
        # plt.hist(point_distances, bins=20, color='skyblue', edgecolor='black')
        # plt.xlabel('Distance to nearest ground truth point')
        # plt.ylabel('Frequency')
        # plt.show()

test_local_maxima([3])
